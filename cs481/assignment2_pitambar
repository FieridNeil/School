"""
Created on Sun Mar 18 00:34:41 2018
CPSC483-Project1
Group Member:
Pitambar Paudel
Hympert Nguyen
Devin Cao
Malik Zubair
"""
###########################
# Import  Generic Modules #
###########################

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Import validation module
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score


######################
# Preprocess dataset #
######################

# Replace all missing data " ?" to Unknown category
dataset = pd.read_csv("Dataset.csv")
for i in range(0, len(dataset.columns)):
    missing = 0
    x = dataset.iloc[:,i].values
    for j in range(0,len(x)):
        if x[j] == ' ?':
            x[j] = " Unknown"
    

# Independent and dependent variables
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

#############################
# Encoding categorical data #
#############################

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Encoding the Independent 
for i in range(0, len(dataset.columns) - 1):
    if type(X[1,i]) == int:
        continue
    labelencoder_X = LabelEncoder()
    X[:, i] = labelencoder_X.fit_transform(X[:, i])




l = [1,2,4,5,6,7]
count = 0 

#One hot encoder with removed dummy trap
for i,j in enumerate(l) :
    onc = OneHotEncoder(categorical_features = [count + j - (2*i)])
    onc.fit(X)
    count = count+ int(onc.n_values_)
    X = onc.fit_transform(X).toarray()
    X= X[:,1:]

# Encoding the Dependent Variable
labelencoder_y = LabelEncoder()
y = labelencoder_y.fit_transform(y)

#split into training and testing set    
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.25)


###############
# Naive Bayes #
###############

from sklearn.naive_bayes import GaussianNB
gnb =  GaussianNB()
y_pred_gaussian =  gnb.fit(Xtrain,ytrain).predict(Xtest)
cvs_gnb = cross_val_score(gnb, X, y, cv = 10)
print("Cross Validation score from Gaussian Naive Bayes method:")  
print(cvs_gnb.mean())          
###########################            
# Decision Tree Induction #
###########################
from sklearn import tree
clf_dec_tree = tree.DecisionTreeClassifier()
clf_dec_tree =  clf_dec_tree.fit(Xtrain,ytrain)
y_pred_dectree_clf=clf_dec_tree.predict(Xtest)
cvs_dectree = cross_val_score(clf_dec_tree, X, y, cv = 10)
print("Cross Validation score from Decision tree classification:")  
print(cvs_dectree.mean())
##########################            
# Multiple layer Perceptron #
##########################
from sklearn.neural_network import MLPClassifier
clf_mlp = MLPClassifier()

clf_mlp.fit(Xtrain,ytrain)
y_pred_mlp =  clf_mlp.predict(Xtest)
cvs_mlp = cross_val_score(clf_mlp, X, y, cv = 10)
print("Cross Validation score from multilayer perceptron method:")  
print(cvs_mlp.mean()) 



